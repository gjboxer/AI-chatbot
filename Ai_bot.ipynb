{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"HrsPOtCkqLEP"},"outputs":[],"source":["import tensorflow\n","import numpy \n","import pandas\n","import nltk\n","import random\n","import json\n","import pickle"]},{"cell_type":"code","source":["from nltk.stem import WordNetLemmatizer"],"metadata":{"id":"eDouzB8RqXZP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"JquhwIV9tqZH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential"],"metadata":{"id":"qK3REMPCxhZT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.layers import Dense, Activation, Dropout\n","from tensorflow.keras.optimizers import SGD"],"metadata":{"id":"DExhhnMMyMGn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lemmatizer = WordNetLemmatizer()"],"metadata":{"id":"yFdEzqaxyW_p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('/content/drive/MyDrive/AI_materials/dataset.json') as jsonfile:\n","  intents = json.load(jsonfile)\n","# intents = json.loads(open('dataset.json').read())"],"metadata":{"id":"TZxDSNZvycGd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["intents"],"metadata":{"id":"ZsIDI0zXyjMD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nltk.download('punkt')"],"metadata":{"id":"F8p4JyqLepWb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["words = []\n","classes =[]\n","documents=[]\n","ignore_letters = [ '!', ',','.', '?']\n","\n","for intent in intents['intents']:\n","  for pattern in intent['patterns']:\n","    word_list = nltk.word_tokenize(pattern)\n","    words.extend(word_list)\n","    documents.append((word_list, intent['tag']))\n","    if intent['tag'] not in classes:\n","      classes.append(intent['tag'])"],"metadata":{"id":"8tK6sX8uyljz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nltk.download('wordnet')\n","nltk.download('omw-1.4')"],"metadata":{"id":"6seGwbYdf7gj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["words = [lemmatizer.lemmatize(word) for word in words if word not in ignore_letters]\n","words = sorted(set(words))"],"metadata":{"id":"Fph9bTeOzV3T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# words"],"metadata":{"id":"yWNMRWXwf2r0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["classes = sorted(set(classes))"],"metadata":{"id":"ElLaECOKgMMU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pickle.dump(words, open('words.pkl', 'wb'))"],"metadata":{"id":"RpPaQPcXgQce"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pickle.dump(classes, open('classes.pkl', 'wb'))"],"metadata":{"id":"psweAWHPgiKz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training = []\n","output_empty = [0]*len(classes)"],"metadata":{"id":"iNsAudtbgt6D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for document in documents:\n","  bag = []\n","  word_patterns = document[0]\n","  word_patterns = [lemmatizer.lemmatize(word.lower()) for word in word_patterns]\n","  for word in words:\n","    bag.append(1) if word in word_patterns else bag.append(0)\n","\n","\n","  output_row = list(output_empty)\n","  output_row[classes.index(document[1])]=1\n","  training.append([bag, output_row])"],"metadata":{"id":"PcEkPZFJg1re"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["random.shuffle(training)\n","training = numpy.array(training)"],"metadata":{"id":"NqPeJqt6hoMN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x = list(training[:,0])\n","train_y = list(training[:, 1])"],"metadata":{"id":"1GtCzzJ9hyb8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()"],"metadata":{"id":"UdAipU0diAiZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.add(Dense(100, input_shape=(len(train_x[0]),), activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(75, activation='relu'))\n","model.add(Dropout(0.3))\n","model.add(Dense(len(train_y[0]), activation='softmax'))"],"metadata":{"id":"zF-ZZZg1iDf1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","hist = model.fit(numpy.array(train_x), numpy.array(train_y), epochs=30, batch_size=5, verbose=1)\n","model.save('chatbotmodel.h5', hist)"],"metadata":{"id":"8aNR100cih5t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"xjWcRAkNMZJc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model is trained and is stored in drive file with the name of chatbotmodel.h5\n","- Mount drive and import the model using pickle"],"metadata":{"id":"hiaupPp_kBc_"}},{"cell_type":"code","source":["from tensorflow.keras.models import load_model"],"metadata":{"id":"iZxUXASYkSO_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lemmatizer = WordNetLemmatizer()"],"metadata":{"id":"v2XUUlJgkc-h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# intents = json.loads(open('/content/drive/MyDrive/AI_materials/dataset.json').read())  # to retrieve from the drive \n","intents = json.loads(open('dataset.json').read()) # to read directly from the same folder"],"metadata":{"id":"YtsP3brukh1G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hist"],"metadata":{"id":"dGNgXUIbkoXR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = load_model('chatbotmodel.h5')"],"metadata":{"id":"BEoILLfukwBY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def clean_up_sentence(sentence):\n","  sentence_words = nltk.word_tokenize(sentence)\n","  sentence_words = [lemmatizer.lemmatize(word) for word in sentence_words]\n","  return sentence_words"],"metadata":{"id":"fWLsUce2kxLj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def bag_of_words(sentence):\n","  sentence_words = clean_up_sentence(sentence)\n","  bag = [0]*len(words)\n","  for w in sentence_words:\n","    for i, word in enumerate(words):\n","      if word == w:\n","        bag[i] = 1\n","\n","  return numpy.array(bag)"],"metadata":{"id":"kOzdTAzdlNbG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_class(sentence):\n","  bow = bag_of_words(sentence)\n","  res = model.predict(numpy.array([bow]))[0]\n","  ERROR_THRESHOLD = 0.21\n","  results = [[i, r] for i, r in enumerate(res) if r>ERROR_THRESHOLD]\n","\n","  results.sort(key=lambda x:x[1], reverse=True)\n","  return_list = []\n","  for r in results:\n","    return_list.append({'intent':classes[r[0]], 'probability':str(r[1])})\n","  return return_list"],"metadata":{"id":"v-fibuHplync"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_response(intents_list, intents_json):\n","  tag = intents_list[0]['intent']\n","  list_of_intents = intents_json['intents']\n","\n","  default_tag = \"\"\n","  flag = 1\n","  for i in list_of_intents:\n","    if i['tag'] == 'error' and flag==1:\n","      default_tag = random.choice(i['responses'])\n","      result = default_tag\n","      flag = 0\n","    if i['tag'] == tag:\n","      result = random.choice(i['responses'])\n","      break\n","  return result"],"metadata":{"id":"MknaSZixmuNM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def bot(): \n","  print(\"Ask Query ......................\")\n","  while True:\n","    message = input(\"| You: \")\n","    if message == \"bye\" or message == \"Goodbye\":\n","      ints = predict_class(message)\n","      res =get_response(ints, intents)\n","      print(\"| Bot: \", res)\n","      print(\"The program ends here!\")\n","      exit()\n","      return\n","    else:\n","      ints = predict_class(message)\n","      res= get_response(ints, intents)\n","      print(\"| Bot: \", res)"],"metadata":{"id":"95tDucXhpK-7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bot()\n"],"metadata":{"id":"x0skP8n9Dtdz"},"execution_count":null,"outputs":[]}]}